# üõ°Ô∏è Strat√©gie de Backup - Kamba Lhains

## Vue d'ensemble

Cette documentation d√©crit la strat√©gie compl√®te de sauvegarde et r√©cup√©ration pour l'application e-commerce Kamba Lhains, couvrant tous les aspects critiques : base de donn√©es, fichiers, configuration et code.

## üéØ Objectifs de sauvegarde

### RTO (Recovery Time Objective)
- **Critique** : < 1 heure (base de donn√©es, commandes)
- **Important** : < 4 heures (fichiers utilisateur, images)
- **Normal** : < 24 heures (logs, analytics)

### RPO (Recovery Point Objective)
- **Transactions e-commerce** : < 5 minutes
- **Donn√©es utilisateur** : < 1 heure
- **Contenu statique** : < 24 heures

## üìä Classification des donn√©es

### üî¥ **Niveau Critique**
- **Base de donn√©es PostgreSQL** (commandes, utilisateurs, paiements)
- **Variables d'environnement** et secrets
- **Configuration Stripe** et cl√©s API

### üü° **Niveau Important**
- **Images produits** et assets utilisateur
- **Logs d'application** et m√©triques
- **Configuration serveur** et middleware

### üü¢ **Niveau Standard**
- **Code source** (d√©j√† versioned sur Git)
- **Logs syst√®me** anciens (> 30 jours)
- **Cache temporaire** et sessions

## üóÑÔ∏è Strat√©gie par composant

### 1. Base de donn√©es PostgreSQL

#### **Sauvegardes automatiques**
```bash
# Sauvegarde quotidienne compl√®te (3h du matin)
0 3 * * * pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME | gzip > /backups/db/daily/kamba_$(date +\%Y\%m\%d).sql.gz

# Sauvegarde incr√©mentale toutes les 4h
0 */4 * * * pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME --serializable-deferrable | gzip > /backups/db/incremental/kamba_$(date +\%Y\%m\%d_\%H).sql.gz
```

#### **R√©plication**
- **Master-Slave** : R√©plication automatique sur serveur secondaire
- **Point-in-Time Recovery** : WAL archiving activ√©
- **Geo-replication** : Backup dans r√©gion diff√©rente

#### **Monitoring**
```sql
-- V√©rification de la r√©plication
SELECT client_addr, state, sent_lsn, write_lsn, flush_lsn, replay_lsn 
FROM pg_stat_replication;

-- V√©rification de l'espace disque
SELECT datname, pg_size_pretty(pg_database_size(datname)) 
FROM pg_database 
WHERE datistemplate = false;
```

### 2. Fichiers et Assets

#### **Structure de backup**
```
/backups/
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ daily/          # Sauvegardes compl√®tes quotidiennes
‚îÇ   ‚îú‚îÄ‚îÄ incremental/    # Sauvegardes incr√©mentales
‚îÇ   ‚îî‚îÄ‚îÄ wal/           # WAL files pour PITR
‚îú‚îÄ‚îÄ files/
‚îÇ   ‚îú‚îÄ‚îÄ images/        # Images produits et utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ uploads/       # Fichiers upload√©s
‚îÇ   ‚îî‚îÄ‚îÄ static/        # Assets statiques
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ env/           # Variables d'environnement
‚îÇ   ‚îú‚îÄ‚îÄ nginx/         # Configuration serveur
‚îÇ   ‚îî‚îÄ‚îÄ ssl/           # Certificats SSL
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ app/           # Logs application
    ‚îú‚îÄ‚îÄ access/        # Logs d'acc√®s
    ‚îî‚îÄ‚îÄ error/         # Logs d'erreur
```

#### **Synchronisation cloud**
```bash
# Sync vers AWS S3 (quotidien)
aws s3 sync /backups/ s3://kamba-lhains-backups/ --delete --storage-class STANDARD_IA

# Sync vers Google Cloud Storage (hebdomadaire)
gsutil -m rsync -r -d /backups/ gs://kamba-lhains-backups-secondary/
```

### 3. Configuration et Secrets

#### **Vault de secrets**
- **HashiCorp Vault** ou **AWS Secrets Manager**
- **Rotation automatique** des cl√©s API
- **Audit trail** complet des acc√®s

#### **Sauvegarde des configurations**
```bash
# Export des variables d'environnement (masqu√©es)
env | grep -E "^(DB_|STRIPE_|NEXTAUTH_)" | sed 's/=.*/=***/' > /backups/config/env_template.txt

# Backup configuration Vercel
vercel env ls --format json > /backups/config/vercel_env.json
```

## ü§ñ Scripts d'automatisation

### Script principal de backup

```bash
#!/bin/bash
# /scripts/backup.sh

set -e

BACKUP_ROOT="/backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="/var/log/backup_$TIMESTAMP.log"

# Configuration
DB_HOST=$DATABASE_HOST
DB_NAME=$DATABASE_NAME
DB_USER=$DATABASE_USER
S3_BUCKET="kamba-lhains-backups"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Backup base de donn√©es
backup_database() {
    log "üóÑÔ∏è  D√©marrage backup base de donn√©es"
    
    local backup_file="$BACKUP_ROOT/db/daily/kamba_$TIMESTAMP.sql.gz"
    mkdir -p "$(dirname "$backup_file")"
    
    if pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" --clean --if-exists | gzip > "$backup_file"; then
        log "‚úÖ Backup DB r√©ussi: $(basename "$backup_file")"
        
        # V√©rification de l'int√©grit√©
        if gunzip -t "$backup_file"; then
            log "‚úÖ V√©rification int√©grit√© OK"
        else
            log "‚ùå Erreur int√©grit√© backup DB"
            return 1
        fi
    else
        log "‚ùå Erreur backup base de donn√©es"
        return 1
    fi
}

# Backup fichiers
backup_files() {
    log "üìÅ D√©marrage backup fichiers"
    
    local dirs=("public/images" "uploads" ".next/static")
    
    for dir in "${dirs[@]}"; do
        if [[ -d "$dir" ]]; then
            local backup_file="$BACKUP_ROOT/files/${dir//\//_}_$TIMESTAMP.tar.gz"
            mkdir -p "$(dirname "$backup_file")"
            
            if tar -czf "$backup_file" "$dir"; then
                log "‚úÖ Backup $dir r√©ussi"
            else
                log "‚ùå Erreur backup $dir"
            fi
        fi
    done
}

# Sync vers cloud
sync_to_cloud() {
    log "‚òÅÔ∏è  Synchronisation vers cloud"
    
    if aws s3 sync "$BACKUP_ROOT/" "s3://$S3_BUCKET/" --delete --storage-class STANDARD_IA; then
        log "‚úÖ Sync S3 r√©ussi"
    else
        log "‚ùå Erreur sync S3"
        return 1
    fi
}

# Nettoyage des anciens backups
cleanup_old_backups() {
    log "üßπ Nettoyage anciens backups"
    
    # Garder 7 jours de backups quotidiens
    find "$BACKUP_ROOT/db/daily" -name "*.sql.gz" -mtime +7 -delete
    
    # Garder 2 jours de backups incr√©mentaux
    find "$BACKUP_ROOT/db/incremental" -name "*.sql.gz" -mtime +2 -delete
    
    # Garder 30 jours de backups fichiers
    find "$BACKUP_ROOT/files" -name "*.tar.gz" -mtime +30 -delete
    
    log "‚úÖ Nettoyage termin√©"
}

# V√©rification de sant√©
health_check() {
    log "üè• V√©rification de sant√©"
    
    # V√©rifier espace disque
    local disk_usage=$(df /backups | tail -1 | awk '{print $5}' | sed 's/%//')
    if [[ $disk_usage -gt 85 ]]; then
        log "‚ö†Ô∏è  Espace disque faible: $disk_usage%"
        # Envoyer alerte
        curl -X POST "$SLACK_WEBHOOK" -H 'Content-type: application/json' \
            --data '{"text":"üö® Backup: Espace disque faible '$disk_usage'%"}'
    fi
    
    # V√©rifier que les backups r√©cents existent
    local recent_backup=$(find "$BACKUP_ROOT/db/daily" -name "*.sql.gz" -mtime -1 | wc -l)
    if [[ $recent_backup -eq 0 ]]; then
        log "‚ùå Aucun backup r√©cent trouv√©"
        return 1
    fi
    
    log "‚úÖ V√©rification de sant√© OK"
}

# Notification
notify_completion() {
    local status=$1
    local message
    
    if [[ $status -eq 0 ]]; then
        message="‚úÖ Backup Kamba Lhains r√©ussi - $TIMESTAMP"
    else
        message="‚ùå Backup Kamba Lhains √©chou√© - $TIMESTAMP"
    fi
    
    # Slack notification
    if [[ -n "$SLACK_WEBHOOK" ]]; then
        curl -X POST "$SLACK_WEBHOOK" -H 'Content-type: application/json' \
            --data '{"text":"'"$message"'"}'
    fi
    
    # Email notification
    if [[ -n "$BACKUP_EMAIL" ]]; then
        echo "$message" | mail -s "Backup Kamba Lhains" "$BACKUP_EMAIL"
    fi
}

# Main execution
main() {
    log "üöÄ D√©marrage backup Kamba Lhains - $TIMESTAMP"
    
    local exit_code=0
    
    backup_database || exit_code=1
    backup_files || exit_code=1
    sync_to_cloud || exit_code=1
    cleanup_old_backups
    health_check || exit_code=1
    
    notify_completion $exit_code
    
    if [[ $exit_code -eq 0 ]]; then
        log "üéâ Backup termin√© avec succ√®s"
    else
        log "üí• Backup termin√© avec erreurs"
    fi
    
    return $exit_code
}

# Gestion des signaux
trap 'log "‚ö†Ô∏è  Backup interrompu"; exit 1' INT TERM

# Lancement
main "$@"
```

### Script de restauration

```bash
#!/bin/bash
# /scripts/restore.sh

set -e

usage() {
    echo "Usage: $0 [options] <backup_date>"
    echo "Options:"
    echo "  -t, --type     Type de restore (db|files|all) [default: all]"
    echo "  -e, --env      Environnement (staging|production) [default: staging]"
    echo "  -f, --force    Force restore without confirmation"
    echo "  -h, --help     Show this help"
    echo ""
    echo "Examples:"
    echo "  $0 20241225_030000                    # Restore compl√®te"
    echo "  $0 -t db -e staging 20241225_030000   # Restore DB seulement"
    echo "  $0 -f latest                          # Restore derni√®re sauvegarde"
}

restore_database() {
    local backup_file=$1
    local target_env=$2
    
    echo "üóÑÔ∏è  Restauration base de donn√©es: $backup_file"
    
    if [[ "$target_env" == "production" ]]; then
        read -p "‚ö†Ô∏è  ATTENTION: Restore en PRODUCTION. Confirmer (yes/no): " confirm
        [[ "$confirm" != "yes" ]] && { echo "Annul√©"; exit 1; }
    fi
    
    # Cr√©ation d'un backup de s√©curit√© avant restore
    local safety_backup="/tmp/safety_backup_$(date +%s).sql.gz"
    echo "üì¶ Cr√©ation backup de s√©curit√©..."
    pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" | gzip > "$safety_backup"
    
    # Restore
    echo "üîÑ Restauration en cours..."
    gunzip -c "$backup_file" | psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME"
    
    echo "‚úÖ Restauration termin√©e"
    echo "üíæ Backup de s√©curit√©: $safety_backup"
}

# ... [suite du script de restore]
```

## üìã Proc√©dures d'urgence

### 1. Perte compl√®te de base de donn√©es

```bash
# 1. Identifier la derni√®re sauvegarde valide
ls -la /backups/db/daily/ | tail -5

# 2. Restaurer depuis S3 si n√©cessaire
aws s3 cp s3://kamba-lhains-backups/db/daily/kamba_20241225_030000.sql.gz /tmp/

# 3. Cr√©er nouvelle base si n√©cessaire
createdb -h $DB_HOST -U $DB_USER kamba_lhains_new

# 4. Restaurer
gunzip -c /tmp/kamba_20241225_030000.sql.gz | psql -h $DB_HOST -U $DB_USER -d kamba_lhains_new

# 5. V√©rifier l'int√©grit√©
psql -h $DB_HOST -U $DB_USER -d kamba_lhains_new -c "SELECT COUNT(*) FROM users;"
```

### 2. Corruption partielle

```sql
-- V√©rification de l'int√©grit√©
SELECT schemaname, tablename, attname, n_distinct, correlation 
FROM pg_stats 
WHERE schemaname = 'public';

-- Reconstruction des index si n√©cessaire
REINDEX DATABASE kamba_lhains;

-- Analyse des statistiques
ANALYZE;
```

## üìä Monitoring et alertes

### M√©triques √† surveiller

```bash
# Espace disque backups
df -h /backups | awk 'NR==2{print $5}' | sed 's/%//'

# √Çge du dernier backup
find /backups/db/daily -name "*.sql.gz" -printf '%T@ %p\n' | sort -n | tail -1

# Taille des backups
du -sh /backups/db/daily/* | tail -7
```

### Dashboard Grafana

```yaml
# prometheus.yml
- job_name: 'backup-monitoring'
  static_configs:
    - targets: ['backup-server:9100']
  metrics_path: /metrics/backup
  scrape_interval: 300s
```

## üîí S√©curit√© et conformit√©

### Chiffrement
- **En transit** : TLS 1.3 pour tous les transferts
- **Au repos** : AES-256 pour stockage S3/GCS
- **Cl√©s** : Rotation automatique tous les 90 jours

### Acc√®s et audit
- **RBAC** : Acc√®s bas√© sur les r√¥les
- **Audit logs** : Tous les acc√®s trac√©s
- **2FA** : Obligatoire pour acc√®s production

### Conformit√© RGPD
- **Anonymisation** : Scripts d'anonymisation des donn√©es sensibles
- **R√©tention** : 7 ans pour donn√©es fiscales, 3 ans pour donn√©es utilisateur
- **Droit √† l'oubli** : Proc√©dure de suppression d√©finitive

## üìÖ Planning de maintenance

### Quotidien (3h00)
- Backup complet base de donn√©es
- Sync incr√©mental fichiers
- V√©rification int√©grit√©

### Hebdomadaire (Dimanche 2h00)
- Backup complet fichiers
- Test de restore sur staging
- Nettoyage anciens backups

### Mensuel (1er du mois)
- Test de restore complet
- Audit des acc√®s
- Mise √† jour documentation

### Trimestriel
- Test de disaster recovery complet
- Review des RTO/RPO
- Formation √©quipe

## üß™ Tests de r√©cup√©ration

### Test mensuel automatis√©

```bash
#!/bin/bash
# test-recovery.sh

STAGING_DB="kamba_staging_test"
LATEST_BACKUP=$(ls -t /backups/db/daily/*.sql.gz | head -1)

echo "üß™ Test de r√©cup√©ration - $(date)"

# 1. Cr√©er DB de test
dropdb --if-exists $STAGING_DB
createdb $STAGING_DB

# 2. Restaurer depuis backup
gunzip -c "$LATEST_BACKUP" | psql -d $STAGING_DB

# 3. Tests de validation
psql -d $STAGING_DB -c "
    SELECT 
        'users' as table_name, 
        count(*) as row_count 
    FROM users
    UNION ALL
    SELECT 'orders', count(*) FROM orders
    UNION ALL  
    SELECT 'products', count(*) FROM products;
"

# 4. Test application
cd /app && DATABASE_URL="postgresql://localhost/$STAGING_DB" npm run test:integration

echo "‚úÖ Test de r√©cup√©ration termin√©"
```

## üìû Contacts d'urgence

### Plan d'escalade
1. **DevOps Engineer** : +33 6 XX XX XX XX
2. **Lead Developer** : +33 6 XX XX XX XX  
3. **CTO** : +33 6 XX XX XX XX
4. **Support AWS** : Enterprise Support Case

### Canaux de communication
- **Slack** : #incidents-backup
- **Email** : backup-alerts@kamba-lhains.com
- **PagerDuty** : Integration configur√©e

---

**üìã Ce document doit √™tre mis √† jour trimestriellement et apr√®s tout incident de production.**

*Derni√®re mise √† jour : 2024-12-25*  
*Version : 1.0*  
*Responsable : DevOps Team*